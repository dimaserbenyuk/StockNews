{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dotenv import load_dotenv\n",
    "from textblob import TextBlob\n",
    "from decimal import Decimal\n",
    "\n",
    "# Загрузка переменных окружения из .env файла\n",
    "load_dotenv()\n",
    "\n",
    "# Инициализация клиента STS и DynamoDB\n",
    "sts_client = boto3.client('sts', region_name=os.getenv('AWS_REGION'))\n",
    "\n",
    "# Принятие роли через STS\n",
    "assumed_role = sts_client.assume_role(\n",
    "    RoleArn=os.getenv('ROLE_ARN'),\n",
    "    RoleSessionName='LambdaNewsAnalyzerSession'\n",
    ")\n",
    "\n",
    "credentials = assumed_role['Credentials']\n",
    "\n",
    "# Инициализация клиента DynamoDB с временными креденшиалами\n",
    "dynamodb = boto3.resource(\n",
    "    'dynamodb',\n",
    "    region_name=os.getenv('AWS_REGION'),\n",
    "    aws_access_key_id=credentials['AccessKeyId'],\n",
    "    aws_secret_access_key=credentials['SecretAccessKey'],\n",
    "    aws_session_token=credentials['SessionToken']\n",
    ")\n",
    "\n",
    "# Получение данных из DynamoDB\n",
    "table = dynamodb.Table(os.getenv('DYNAMODB_TABLE'))\n",
    "\n",
    "def fetch_data():\n",
    "    response = table.scan()\n",
    "    items = response.get('Items', [])\n",
    "    return items\n",
    "\n",
    "# Подготовка данных для обучения\n",
    "def prepare_data(items):\n",
    "    # Преобразуем данные в numpy массив\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for item in items:\n",
    "        # Текстовые данные (описание) и метки (настроение)\n",
    "        description = item['description']\n",
    "        sentiment = float(item['sentiment'])\n",
    "\n",
    "        # Добавляем описание и настроение в списки\n",
    "        X.append(description)\n",
    "        y.append(sentiment)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Определение модели\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(X_train, y_train, epochs=100):\n",
    "    model = SentimentModel(input_size=X_train.shape[1])  # Укажите размер входа\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Обучение\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train.unsqueeze(1))  # Убедитесь, что y_train имеет нужную размерность\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "# Визуализация графика потерь\n",
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses, label='Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Получение данных\n",
    "    items = fetch_data()\n",
    "    X, y = prepare_data(items)\n",
    "\n",
    "    # Преобразование текстов в векторы (это необходимо для обучения модели)\n",
    "    # Здесь может быть использована более сложная обработка текста, например, TF-IDF или Word Embeddings\n",
    "    # Это может быть сделано с помощью библиотеки sklearn или gensim\n",
    "    # Пример простого кодирования (вам нужно будет использовать векторизацию текстов)\n",
    "    \n",
    "    # Например, простой способ векторизации (это нужно заменить на TF-IDF или аналог)\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_vectorized = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "    # Разделение на обучающий и тестовый наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Обучение модели\n",
    "    model, losses = train_model(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "\n",
    "    # Визуализация графика потерь\n",
    "    plot_losses(losses)\n",
    "\n",
    "    # Оценка модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(torch.FloatTensor(X_test))\n",
    "        # Здесь можно добавить код для оценки модели, например, расчет RMSE или R^2\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
